{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset is already downloaded and extracted.\n",
      "Current path is: /Users/brian/DeePMD-kit_Tutorial\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the dataset URL and the paths\n",
    "dataset_url = \"https://bohrium-api.dp.tech/ds-dl/DeePMD-kit-Tutorial-a8z5-v1.zip\"\n",
    "zip_file_name = \"DeePMD-kit-Tutorial-a8z5-v1.zip\"\n",
    "dataset_directory = \"DeePMD-kit_Tutorial\"\n",
    "home_directory = os.path.expanduser(\"~\")  # Use home directory\n",
    "local_zip_path = os.path.join(home_directory, zip_file_name)\n",
    "extract_path = os.path.join(home_directory, \"DeePMD-kit_Tutorial\")\n",
    "\n",
    "# Ensure the base directory exists\n",
    "if not os.path.exists(extract_path):\n",
    "    os.makedirs(extract_path)\n",
    "    print(f\"Created directory: {extract_path}\")\n",
    "\n",
    "# Check if the dataset directory exists to avoid re-downloading and re-extracting\n",
    "if not os.path.isdir(os.path.join(extract_path, dataset_directory)):\n",
    "    # Download the dataset if it doesn't already exist\n",
    "    if not os.path.isfile(local_zip_path):\n",
    "        print(\"Downloading dataset...\")\n",
    "        os.system(f\"wget -q -O {local_zip_path} {dataset_url}\")\n",
    "    \n",
    "    # Extract the dataset\n",
    "    if os.path.isfile(local_zip_path):\n",
    "        print(\"Extracting dataset...\")\n",
    "        os.system(f\"unzip -q -n {local_zip_path} -d {extract_path}\")\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Failed to download the file from {dataset_url}\")\n",
    "else:\n",
    "    print(\"Dataset is already downloaded and extracted.\")\n",
    "\n",
    "# Change the current working directory\n",
    "os.chdir(extract_path)\n",
    "print(f\"Current path is: {os.getcwd()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mDeePMD-kit_Tutorial\u001b[0m\n",
      "├── \u001b[01;34m00.data\u001b[0m\n",
      "├── \u001b[01;34m01.train\u001b[0m\n",
      "├── \u001b[01;34m01.train.finished\u001b[0m\n",
      "├── \u001b[01;34m02.lmp\u001b[0m\n",
      "└── \u001b[01;34m02.lmp.finished\u001b[0m\n",
      "\n",
      "6 directories, 0 files\n"
     ]
    }
   ],
   "source": [
    "! tree DeePMD-kit_Tutorial -L 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mDeePMD-kit_Tutorial/00.data\u001b[0m\n",
      "├── \u001b[01;34mabacus_md\u001b[0m\n",
      "├── \u001b[01;34mtraining_data\u001b[0m\n",
      "└── \u001b[01;34mvalidation_data\u001b[0m\n",
      "\n",
      "4 directories, 0 files\n"
     ]
    }
   ],
   "source": [
    "! tree DeePMD-kit_Tutorial/00.data -L 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# the data contains 201 frames\n",
      "# the training data contains 161 frames\n",
      "# the validation data contains 40 frames\n"
     ]
    }
   ],
   "source": [
    "import dpdata\n",
    "import numpy as np\n",
    "\n",
    "# load data of abacus/md format\n",
    "data = dpdata.LabeledSystem(\"DeePMD-kit_Tutorial/00.data/abacus_md\", fmt=\"abacus/md\")\n",
    "print(\"# the data contains %d frames\" % len(data))\n",
    "\n",
    "# random choose 40 index for validation_data\n",
    "rng = np.random.default_rng()\n",
    "index_validation = rng.choice(201, size=40, replace=False)\n",
    "\n",
    "# other indexes are training_data\n",
    "index_training = list(set(range(201)) - set(index_validation))\n",
    "data_training = data.sub_system(index_training)\n",
    "data_validation = data.sub_system(index_validation)\n",
    "\n",
    "# all training data put into directory:\"training_data\"\n",
    "data_training.to_deepmd_npy(\"DeePMD-kit_Tutorial/00.data/training_data\")\n",
    "\n",
    "# all validation data put into directory:\"validation_data\"\n",
    "data_validation.to_deepmd_npy(\"DeePMD-kit_Tutorial/00.data/validation_data\")\n",
    "\n",
    "print(\"# the training data contains %d frames\" % len(data_training))\n",
    "print(\"# the validation data contains %d frames\" % len(data_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mDeePMD-kit_Tutorial/00.data/\u001b[0m\n",
      "├── \u001b[01;34mabacus_md\u001b[0m\n",
      "├── \u001b[01;34mtraining_data\u001b[0m\n",
      "└── \u001b[01;34mvalidation_data\u001b[0m\n",
      "\n",
      "4 directories, 0 files\n"
     ]
    }
   ],
   "source": [
    "! tree DeePMD-kit_Tutorial/00.data/ -L 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mDeePMD-kit_Tutorial/00.data/training_data\u001b[0m\n",
      "├── \u001b[01;34mset.000\u001b[0m\n",
      "├── \u001b[00mtype.raw\u001b[0m\n",
      "└── \u001b[00mtype_map.raw\u001b[0m\n",
      "\n",
      "2 directories, 2 files\n"
     ]
    }
   ],
   "source": [
    "! tree DeePMD-kit_Tutorial/00.data/training_data -L 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "! cat DeePMD-kit_Tutorial/00.data/training_data/type.raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H\n",
      "C\n"
     ]
    }
   ],
   "source": [
    "! cat DeePMD-kit_Tutorial/00.data/training_data/type_map.raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Package(s) not found: dargs\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting dargs\n",
      "  Downloading dargs-0.4.10-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting typeguard>=4 (from dargs)\n",
      "  Downloading typeguard-4.4.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting typing-extensions>=4.10.0 (from typeguard>=4->dargs)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Downloading dargs-0.4.10-py3-none-any.whl (27 kB)\n",
      "Downloading typeguard-4.4.1-py3-none-any.whl (35 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: typing-extensions, typeguard, dargs\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.9.0\n",
      "    Uninstalling typing_extensions-4.9.0:\n",
      "      Successfully uninstalled typing_extensions-4.9.0\n",
      "Successfully installed dargs-0.4.10 typeguard-4.4.1 typing-extensions-4.12.2\n"
     ]
    }
   ],
   "source": [
    "# Check dargs version and Install\n",
    "!pip show dargs || pip install --upgrade dargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dargs-codeblock {\n",
       "  width: 100%;\n",
       "  background-color: #f9f9f9;\n",
       "  border-color: #f9f9f9;\n",
       "  color: #000000;\n",
       "}\n",
       ".dargs-codeblock::before {\n",
       "  counter-reset: listing;\n",
       "}\n",
       ".dargs-codeblock code.dargs-linebegin {\n",
       "  counter-increment: listing;\n",
       "}\n",
       ".dargs-codeblock code.dargs-linebegin::before {\n",
       "  content: counter(listing) \" \";\n",
       "  display: inline-block;\n",
       "  width: 2em;\n",
       "  padding-left: auto;\n",
       "  margin-left: auto;\n",
       "  text-align: right;\n",
       "  color: #6e7781;\n",
       "}\n",
       ".dargs-codeblock code.dargs-code {\n",
       "  padding-left: 0;\n",
       "  padding-right: 0;\n",
       "  margin-left: 0;\n",
       "  margin-right: 0;\n",
       "  background-color: #f9f9f9;\n",
       "  border-color: #f9f9f9;\n",
       "  color: #000000;\n",
       "}\n",
       ".dargs-codeblock .dargs-key {\n",
       "  position: relative;\n",
       "  display: inline-block;\n",
       "  border-bottom: 1px dotted black;\n",
       "}\n",
       ".dargs-codeblock .dargs-key code.dargs-code {\n",
       "  color: #0550ae;\n",
       "}\n",
       ".dargs-codeblock .dargs-key .dargs-doc {\n",
       "  visibility: hidden;\n",
       "  width: 600px;\n",
       "  background-color: black;\n",
       "  color: #fff;\n",
       "  padding: 1em 1em;\n",
       "  border-radius: 6px;\n",
       "  position: absolute;\n",
       "  z-index: 1;\n",
       "}\n",
       ".dargs-codeblock .dargs-key:hover .dargs-doc {\n",
       "  visibility: visible;\n",
       "}\n",
       ".dargs-codeblock .dargs-key .dargs-doc .dargs-doc-code {\n",
       "  color: #bbbbff;\n",
       "}\n",
       "</style>\n",
       "<div class=\"dargs-codeblock\"><code class=\"dargs-code dargs-linebegin\"></code><code class=\"dargs-code\">{</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;</code><span><code class=\"dargs-code\">\"_comment\"</code></span><code class=\"dargs-code\">: </code><code class=\"dargs-code\">\"that's&nbsp;all\",</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;</code><span class=\"dargs-key\"><code class=\"dargs-code\">\"model\"</code><span class=\"dargs-doc\">model: <br/>    type: <span class=\"dargs-doc-code\">dict</span></span></span><code class=\"dargs-code\">: </code><code class=\"dargs-code\">{</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;</code><span class=\"dargs-key\"><code class=\"dargs-code\">\"type_map\"</code><span class=\"dargs-doc\">type_map: <br/>    type: <span class=\"dargs-doc-code\">typing.List[str]</span>, optional<hr/>A list of strings. Give the name to each type of atoms. It is noted that the number of atom type of training system must be less than 128 in a GPU environment. If not given, type.raw in each system should use the same type indexes, and type_map.raw will take no effect.</span></span><code class=\"dargs-code\">: </code><code class=\"dargs-code\">[</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class=\"dargs-code\">&nbsp;&nbsp;\"H\",</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class=\"dargs-code\">&nbsp;&nbsp;\"C\"</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class=\"dargs-code\">],</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;</code><span class=\"dargs-key\"><code class=\"dargs-code\">\"descriptor\"</code><span class=\"dargs-doc\">descriptor: <br/>    type: <span class=\"dargs-doc-code\">dict</span><hr/>The descriptor of atomic environment.</span></span><code class=\"dargs-code\">: </code><code class=\"dargs-code\">{</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><span class=\"dargs-key\"><code class=\"dargs-code\">\"type\"</code><span class=\"dargs-doc\">type:<br/>type: <span class=\"dargs-doc-code\">str</span><hr/>The type of the descritpor. See explanation below. <br/>- <span class=\"dargs-doc-code\">loc_frame</span>: Defines a local frame at each atom, and the compute the descriptor as local coordinates under this frame.<br/>- <span class=\"dargs-doc-code\">se_e2_a</span>: Used by the smooth edition of Deep Potential. The full relative coordinates are used to construct the descriptor.<br/>- <span class=\"dargs-doc-code\">se_e2_r</span>: Used by the smooth edition of Deep Potential. Only the distance between atoms is used to construct the descriptor.<br/>- <span class=\"dargs-doc-code\">se_e3</span>: Used by the smooth edition of Deep Potential. The full relative coordinates are used to construct the descriptor. Three-body embedding will be used by this descriptor.<br/>- <span class=\"dargs-doc-code\">se_a_tpe</span>: Used by the smooth edition of Deep Potential. The full relative coordinates are used to construct the descriptor. Type embedding will be used by this descriptor.<br/>- <span class=\"dargs-doc-code\">se_atten</span>: Used by the smooth edition of Deep Potential. The full relative coordinates are used to construct the descriptor. Attention mechanism will be used by this descriptor.<br/>- <span class=\"dargs-doc-code\">se_atten_v2</span>: Used by the smooth edition of Deep Potential. The full relative coordinates are used to construct the descriptor. Attention mechanism with new modifications will be used by this descriptor.<br/>- <span class=\"dargs-doc-code\">se_a_mask</span>: Used by the smooth edition of Deep Potential. It can accept a variable number of atoms in a frame (Non-PBC system). <i>aparam</i> are required as an indicator matrix for the real/virtual sign of input atoms. <br/>- <span class=\"dargs-doc-code\">hybrid</span>: Concatenate of a list of descriptors as a new descriptor.</span></span><code class=\"dargs-code\">: </code><code class=\"dargs-code\">\"se_e2_a\",</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><span class=\"dargs-key\"><code class=\"dargs-code\">\"sel\"</code><span class=\"dargs-doc\">sel: <br/>    type: <span class=\"dargs-doc-code\">typing.List[int]</span> | <span class=\"dargs-doc-code\">str</span>, optional, default: <span class=\"dargs-doc-code\">auto</span><hr/>This parameter set the number of selected neighbors for each type of atom. It can be:<br/>    - <span class=\"dargs-doc-code\">List[int]</span>. The length of the list should be the same as the number of atom types in the system. <span class=\"dargs-doc-code\">sel[i]</span> gives the selected number of type-i neighbors. <span class=\"dargs-doc-code\">sel[i]</span> is recommended to be larger than the maximally possible number of type-i neighbors in the cut-off radius. It is noted that the total sel value must be less than 4096 in a GPU environment.<br/>    - <span class=\"dargs-doc-code\">str</span>. Can be &quot;auto:factor&quot; or &quot;auto&quot;. &quot;factor&quot; is a float number larger than 1. This option will automatically determine the <span class=\"dargs-doc-code\">sel</span>. In detail it counts the maximal number of neighbors with in the cutoff radius for each type of neighbor, then multiply the maximum by the &quot;factor&quot;. Finally the number is wraped up to 4 divisible. The option &quot;auto&quot; is equivalent to &quot;auto:1.1&quot;.</span></span><code class=\"dargs-code\">: </code><code class=\"dargs-code\">\"auto\",</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><span class=\"dargs-key\"><code class=\"dargs-code\">\"rcut_smth\"</code><span class=\"dargs-doc\">rcut_smth: <br/>    type: <span class=\"dargs-doc-code\">float</span>, optional, default: <span class=\"dargs-doc-code\">0.5</span><hr/>Where to start smoothing. For example the 1/r term is smoothed from <span class=\"dargs-doc-code\">rcut</span> to <span class=\"dargs-doc-code\">rcut_smth</span></span></span><code class=\"dargs-code\">: </code><code class=\"dargs-code\">0.5,</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><span class=\"dargs-key\"><code class=\"dargs-code\">\"rcut\"</code><span class=\"dargs-doc\">rcut: <br/>    type: <span class=\"dargs-doc-code\">float</span>, optional, default: <span class=\"dargs-doc-code\">6.0</span><hr/>The cut-off radius.</span></span><code class=\"dargs-code\">: </code><code class=\"dargs-code\">6.0,</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><span class=\"dargs-key\"><code class=\"dargs-code\">\"neuron\"</code><span class=\"dargs-doc\">neuron: <br/>    type: <span class=\"dargs-doc-code\">typing.List[int]</span>, optional, default: <span class=\"dargs-doc-code\">[10, 20, 40]</span><hr/>Number of neurons in each hidden layers of the embedding net. When two layers are of the same size or one layer is twice as large as the previous layer, a skip connection is built.</span></span><code class=\"dargs-code\">: </code><code class=\"dargs-code\">[</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class=\"dargs-code\">&nbsp;&nbsp;25,</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class=\"dargs-code\">&nbsp;&nbsp;50,</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class=\"dargs-code\">&nbsp;&nbsp;100</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class=\"dargs-code\">],</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><span class=\"dargs-key\"><code class=\"dargs-code\">\"resnet_dt\"</code><span class=\"dargs-doc\">resnet_dt: <br/>    type: <span class=\"dargs-doc-code\">bool</span>, optional, default: <span class=\"dargs-doc-code\">False</span><hr/>Whether to use a &quot;Timestep&quot; in the skip connection</span></span><code class=\"dargs-code\">: </code><code class=\"dargs-code\">false,</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><span class=\"dargs-key\"><code class=\"dargs-code\">\"axis_neuron\"</code><span class=\"dargs-doc\">axis_neuron: <br/>    type: <span class=\"dargs-doc-code\">int</span>, optional, default: <span class=\"dargs-doc-code\">4</span>, alias: <i>n_axis_neuron</i><hr/>Size of the submatrix of G (embedding matrix).</span></span><code class=\"dargs-code\">: </code><code class=\"dargs-code\">16,</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><span class=\"dargs-key\"><code class=\"dargs-code\">\"seed\"</code><span class=\"dargs-doc\">seed: <br/>    type: <span class=\"dargs-doc-code\">NoneType</span> | <span class=\"dargs-doc-code\">int</span>, optional<hr/>Random seed for parameter initialization</span></span><code class=\"dargs-code\">: </code><code class=\"dargs-code\">1,</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><span><code class=\"dargs-code\">\"_comment\"</code></span><code class=\"dargs-code\">: </code><code class=\"dargs-code\">\"&nbsp;that's&nbsp;all\"</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class=\"dargs-code\">},</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;</code><span class=\"dargs-key\"><code class=\"dargs-code\">\"fitting_net\"</code><span class=\"dargs-doc\">fitting_net: <br/>    type: <span class=\"dargs-doc-code\">dict</span><hr/>The fitting of physical properties.</span></span><code class=\"dargs-code\">: </code><code class=\"dargs-code\">{</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><span class=\"dargs-key\"><code class=\"dargs-code\">\"neuron\"</code><span class=\"dargs-doc\">neuron: <br/>    type: <span class=\"dargs-doc-code\">typing.List[int]</span>, optional, default: <span class=\"dargs-doc-code\">[120, 120, 120]</span>, alias: <i>n_neuron</i><hr/>The number of neurons in each hidden layers of the fitting net. When two hidden layers are of the same size, a skip connection is built.</span></span><code class=\"dargs-code\">: </code><code class=\"dargs-code\">[</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class=\"dargs-code\">&nbsp;&nbsp;240,</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class=\"dargs-code\">&nbsp;&nbsp;240,</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class=\"dargs-code\">&nbsp;&nbsp;240</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class=\"dargs-code\">],</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><span class=\"dargs-key\"><code class=\"dargs-code\">\"resnet_dt\"</code><span class=\"dargs-doc\">resnet_dt: <br/>    type: <span class=\"dargs-doc-code\">bool</span>, optional, default: <span class=\"dargs-doc-code\">True</span><hr/>Whether to use a &quot;Timestep&quot; in the skip connection</span></span><code class=\"dargs-code\">: </code><code class=\"dargs-code\">true,</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><span class=\"dargs-key\"><code class=\"dargs-code\">\"seed\"</code><span class=\"dargs-doc\">seed: <br/>    type: <span class=\"dargs-doc-code\">NoneType</span> | <span class=\"dargs-doc-code\">int</span>, optional<hr/>Random seed for parameter initialization of the fitting net</span></span><code class=\"dargs-code\">: </code><code class=\"dargs-code\">1,</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><span><code class=\"dargs-code\">\"_comment\"</code></span><code class=\"dargs-code\">: </code><code class=\"dargs-code\">\"&nbsp;that's&nbsp;all\"</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class=\"dargs-code\">},</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;</code><span><code class=\"dargs-code\">\"_comment\"</code></span><code class=\"dargs-code\">: </code><code class=\"dargs-code\">\"&nbsp;that's&nbsp;all\"</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;</code><code class=\"dargs-code\">},</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;</code><span class=\"dargs-key\"><code class=\"dargs-code\">\"learning_rate\"</code><span class=\"dargs-doc\">learning_rate: <br/>    type: <span class=\"dargs-doc-code\">dict</span>, optional<hr/>The definitio of learning rate</span></span><code class=\"dargs-code\">: </code><code class=\"dargs-code\">{</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;</code><span class=\"dargs-key\"><code class=\"dargs-code\">\"type\"</code><span class=\"dargs-doc\">type:<br/>type: <span class=\"dargs-doc-code\">str</span>, default: <span class=\"dargs-doc-code\">exp</span><hr/>The type of the learning rate.</span></span><code class=\"dargs-code\">: </code><code class=\"dargs-code\">\"exp\",</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;</code><span class=\"dargs-key\"><code class=\"dargs-code\">\"decay_steps\"</code><span class=\"dargs-doc\">decay_steps: <br/>    type: <span class=\"dargs-doc-code\">int</span>, optional, default: <span class=\"dargs-doc-code\">5000</span><hr/>The learning rate is decaying every this number of training steps.</span></span><code class=\"dargs-code\">: </code><code class=\"dargs-code\">50,</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;</code><span class=\"dargs-key\"><code class=\"dargs-code\">\"start_lr\"</code><span class=\"dargs-doc\">start_lr: <br/>    type: <span class=\"dargs-doc-code\">float</span>, optional, default: <span class=\"dargs-doc-code\">0.001</span><hr/>The learning rate at the start of the training.</span></span><code class=\"dargs-code\">: </code><code class=\"dargs-code\">0.001,</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;</code><span class=\"dargs-key\"><code class=\"dargs-code\">\"stop_lr\"</code><span class=\"dargs-doc\">stop_lr: <br/>    type: <span class=\"dargs-doc-code\">float</span>, optional, default: <span class=\"dargs-doc-code\">1e-08</span><hr/>The desired learning rate at the end of the training.</span></span><code class=\"dargs-code\">: </code><code class=\"dargs-code\">3.51e-08,</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;</code><span><code class=\"dargs-code\">\"_comment\"</code></span><code class=\"dargs-code\">: </code><code class=\"dargs-code\">\"that's&nbsp;all\"</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;</code><code class=\"dargs-code\">},</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;</code><span class=\"dargs-key\"><code class=\"dargs-code\">\"loss\"</code><span class=\"dargs-doc\">loss: <br/>    type: <span class=\"dargs-doc-code\">dict</span>, optional<hr/>The definition of loss function. The loss type should be set to <span class=\"dargs-doc-code\">tensor</span>, <span class=\"dargs-doc-code\">ener</span> or left unset.</span></span><code class=\"dargs-code\">: </code><code class=\"dargs-code\">{</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;</code><span class=\"dargs-key\"><code class=\"dargs-code\">\"type\"</code><span class=\"dargs-doc\">type:<br/>type: <span class=\"dargs-doc-code\">str</span>, default: <span class=\"dargs-doc-code\">ener</span><hr/>The type of the loss. When the fitting type is <span class=\"dargs-doc-code\">ener</span>, the loss type should be set to <span class=\"dargs-doc-code\">ener</span> or left unset. When the fitting type is <span class=\"dargs-doc-code\">dipole</span> or <span class=\"dargs-doc-code\">polar</span>, the loss type should be set to <span class=\"dargs-doc-code\">tensor</span>.</span></span><code class=\"dargs-code\">: </code><code class=\"dargs-code\">\"ener\",</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;</code><span class=\"dargs-key\"><code class=\"dargs-code\">\"start_pref_e\"</code><span class=\"dargs-doc\">start_pref_e: <br/>    type: <span class=\"dargs-doc-code\">int</span> | <span class=\"dargs-doc-code\">float</span>, optional, default: <span class=\"dargs-doc-code\">0.02</span><hr/>The prefactor of energy loss at the start of the training. Should be larger than or equal to 0. If set to none-zero value, the energy label should be provided by file energy.npy in each data system. If both start_pref_e and limit_pref_e are set to 0, then the energy will be ignored.</span></span><code class=\"dargs-code\">: </code><code class=\"dargs-code\">0.02,</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;</code><span class=\"dargs-key\"><code class=\"dargs-code\">\"limit_pref_e\"</code><span class=\"dargs-doc\">limit_pref_e: <br/>    type: <span class=\"dargs-doc-code\">int</span> | <span class=\"dargs-doc-code\">float</span>, optional, default: <span class=\"dargs-doc-code\">1.0</span><hr/>The prefactor of energy loss at the limit of the training, Should be larger than or equal to 0. i.e. the training step goes to infinity.</span></span><code class=\"dargs-code\">: </code><code class=\"dargs-code\">1,</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;</code><span class=\"dargs-key\"><code class=\"dargs-code\">\"start_pref_f\"</code><span class=\"dargs-doc\">start_pref_f: <br/>    type: <span class=\"dargs-doc-code\">int</span> | <span class=\"dargs-doc-code\">float</span>, optional, default: <span class=\"dargs-doc-code\">1000</span><hr/>The prefactor of force loss at the start of the training. Should be larger than or equal to 0. If set to none-zero value, the force label should be provided by file force.npy in each data system. If both start_pref_f and limit_pref_f are set to 0, then the force will be ignored.</span></span><code class=\"dargs-code\">: </code><code class=\"dargs-code\">1000,</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;</code><span class=\"dargs-key\"><code class=\"dargs-code\">\"limit_pref_f\"</code><span class=\"dargs-doc\">limit_pref_f: <br/>    type: <span class=\"dargs-doc-code\">int</span> | <span class=\"dargs-doc-code\">float</span>, optional, default: <span class=\"dargs-doc-code\">1.0</span><hr/>The prefactor of force loss at the limit of the training, Should be larger than or equal to 0. i.e. the training step goes to infinity.</span></span><code class=\"dargs-code\">: </code><code class=\"dargs-code\">1,</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;</code><span class=\"dargs-key\"><code class=\"dargs-code\">\"start_pref_v\"</code><span class=\"dargs-doc\">start_pref_v: <br/>    type: <span class=\"dargs-doc-code\">int</span> | <span class=\"dargs-doc-code\">float</span>, optional, default: <span class=\"dargs-doc-code\">0.0</span><hr/>The prefactor of virial loss at the start of the training. Should be larger than or equal to 0. If set to none-zero value, the virial label should be provided by file virial.npy in each data system. If both start_pref_v and limit_pref_v are set to 0, then the virial will be ignored.</span></span><code class=\"dargs-code\">: </code><code class=\"dargs-code\">0,</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;</code><span class=\"dargs-key\"><code class=\"dargs-code\">\"limit_pref_v\"</code><span class=\"dargs-doc\">limit_pref_v: <br/>    type: <span class=\"dargs-doc-code\">int</span> | <span class=\"dargs-doc-code\">float</span>, optional, default: <span class=\"dargs-doc-code\">0.0</span><hr/>The prefactor of virial loss at the limit of the training, Should be larger than or equal to 0. i.e. the training step goes to infinity.</span></span><code class=\"dargs-code\">: </code><code class=\"dargs-code\">0,</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;</code><span><code class=\"dargs-code\">\"_comment\"</code></span><code class=\"dargs-code\">: </code><code class=\"dargs-code\">\"&nbsp;that's&nbsp;all\"</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;</code><code class=\"dargs-code\">},</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;</code><span class=\"dargs-key\"><code class=\"dargs-code\">\"training\"</code><span class=\"dargs-doc\">training: <br/>    type: <span class=\"dargs-doc-code\">dict</span><hr/>The training options.</span></span><code class=\"dargs-code\">: </code><code class=\"dargs-code\">{</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;</code><span class=\"dargs-key\"><code class=\"dargs-code\">\"training_data\"</code><span class=\"dargs-doc\">training_data: <br/>    type: <span class=\"dargs-doc-code\">dict</span>, optional<hr/>Configurations of training data.</span></span><code class=\"dargs-code\">: </code><code class=\"dargs-code\">{</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><span class=\"dargs-key\"><code class=\"dargs-code\">\"systems\"</code><span class=\"dargs-doc\">systems: <br/>    type: <span class=\"dargs-doc-code\">typing.List[str]</span> | <span class=\"dargs-doc-code\">str</span><hr/>The data systems for training. This key can be provided with a list that specifies the systems, or be provided with a string by which the prefix of all systems are given and the list of the systems is automatically generated.</span></span><code class=\"dargs-code\">: </code><code class=\"dargs-code\">[</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class=\"dargs-code\">&nbsp;&nbsp;\"../00.data/training_data\"</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class=\"dargs-code\">],</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><span class=\"dargs-key\"><code class=\"dargs-code\">\"batch_size\"</code><span class=\"dargs-doc\">batch_size: <br/>    type: <span class=\"dargs-doc-code\">typing.List[int]</span> | <span class=\"dargs-doc-code\">int</span> | <span class=\"dargs-doc-code\">str</span>, optional, default: <span class=\"dargs-doc-code\">auto</span><hr/>This key can be <br/>- list: the length of which is the same as the <span class=\"dargs-doc-code\">systems &lt;training/training_data/systems_&gt;</span>_. The batch size of each system is given by the elements of the list.<br/>- int: all <span class=\"dargs-doc-code\">systems &lt;training/training_data/systems_&gt;</span>_ use the same batch size.<br/>- string &quot;auto&quot;: automatically determines the batch size so that the batch_size times the number of atoms in the system is no less than 32.<br/>- string &quot;auto:N&quot;: automatically determines the batch size so that the batch_size times the number of atoms in the system is no less than N.<br/>- string &quot;mixed:N&quot;: the batch data will be sampled from all systems and merged into a mixed system with the batch size N. Only support the se_atten descriptor.<br/>If MPI is used, the value should be considered as the batch size per task.</span></span><code class=\"dargs-code\">: </code><code class=\"dargs-code\">\"auto\",</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><span><code class=\"dargs-code\">\"_comment\"</code></span><code class=\"dargs-code\">: </code><code class=\"dargs-code\">\"that's&nbsp;all\"</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class=\"dargs-code\">},</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;</code><span class=\"dargs-key\"><code class=\"dargs-code\">\"validation_data\"</code><span class=\"dargs-doc\">validation_data: <br/>    type: <span class=\"dargs-doc-code\">NoneType</span> | <span class=\"dargs-doc-code\">dict</span>, optional, default: <span class=\"dargs-doc-code\">None</span><hr/>Configurations of validation data. Similar to that of training data, except that a <span class=\"dargs-doc-code\">numb_btch</span> argument may be configured</span></span><code class=\"dargs-code\">: </code><code class=\"dargs-code\">{</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><span class=\"dargs-key\"><code class=\"dargs-code\">\"systems\"</code><span class=\"dargs-doc\">systems: <br/>    type: <span class=\"dargs-doc-code\">typing.List[str]</span> | <span class=\"dargs-doc-code\">str</span><hr/>The data systems for validation. This key can be provided with a list that specifies the systems, or be provided with a string by which the prefix of all systems are given and the list of the systems is automatically generated.</span></span><code class=\"dargs-code\">: </code><code class=\"dargs-code\">[</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class=\"dargs-code\">&nbsp;&nbsp;\"../00.data/validation_data\"</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class=\"dargs-code\">],</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><span class=\"dargs-key\"><code class=\"dargs-code\">\"batch_size\"</code><span class=\"dargs-doc\">batch_size: <br/>    type: <span class=\"dargs-doc-code\">typing.List[int]</span> | <span class=\"dargs-doc-code\">int</span> | <span class=\"dargs-doc-code\">str</span>, optional, default: <span class=\"dargs-doc-code\">auto</span><hr/>This key can be <br/>- list: the length of which is the same as the <span class=\"dargs-doc-code\">systems &lt;training/validation_data/systems_&gt;</span>_. The batch size of each system is given by the elements of the list.<br/>- int: all <span class=\"dargs-doc-code\">systems &lt;training/validation_data/systems_&gt;</span>_ use the same batch size.<br/>- string &quot;auto&quot;: automatically determines the batch size so that the batch_size times the number of atoms in the system is no less than 32.<br/>- string &quot;auto:N&quot;: automatically determines the batch size so that the batch_size times the number of atoms in the system is no less than N.</span></span><code class=\"dargs-code\">: </code><code class=\"dargs-code\">\"auto\",</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><span class=\"dargs-key\"><code class=\"dargs-code\">\"numb_btch\"</code><span class=\"dargs-doc\">numb_btch: <br/>    type: <span class=\"dargs-doc-code\">int</span>, optional, default: <span class=\"dargs-doc-code\">1</span>, alias: <i>numb_batch</i><hr/>An integer that specifies the number of batches to be sampled for each validation period.</span></span><code class=\"dargs-code\">: </code><code class=\"dargs-code\">1,</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><span><code class=\"dargs-code\">\"_comment\"</code></span><code class=\"dargs-code\">: </code><code class=\"dargs-code\">\"that's&nbsp;all\"</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class=\"dargs-code\">},</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;</code><span class=\"dargs-key\"><code class=\"dargs-code\">\"numb_steps\"</code><span class=\"dargs-doc\">numb_steps: <br/>    type: <span class=\"dargs-doc-code\">int</span>, alias: <i>stop_batch</i><hr/>Number of training batch. Each training uses one batch of data.</span></span><code class=\"dargs-code\">: </code><code class=\"dargs-code\">10000,</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;</code><span class=\"dargs-key\"><code class=\"dargs-code\">\"seed\"</code><span class=\"dargs-doc\">seed: <br/>    type: <span class=\"dargs-doc-code\">NoneType</span> | <span class=\"dargs-doc-code\">int</span>, optional<hr/>The random seed for getting frames from the training data set.</span></span><code class=\"dargs-code\">: </code><code class=\"dargs-code\">10,</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;</code><span class=\"dargs-key\"><code class=\"dargs-code\">\"disp_file\"</code><span class=\"dargs-doc\">disp_file: <br/>    type: <span class=\"dargs-doc-code\">str</span>, optional, default: <span class=\"dargs-doc-code\">lcurve.out</span><hr/>The file for printing learning curve.</span></span><code class=\"dargs-code\">: </code><code class=\"dargs-code\">\"lcurve.out\",</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;</code><span class=\"dargs-key\"><code class=\"dargs-code\">\"disp_freq\"</code><span class=\"dargs-doc\">disp_freq: <br/>    type: <span class=\"dargs-doc-code\">int</span>, optional, default: <span class=\"dargs-doc-code\">1000</span><hr/>The frequency of printing learning curve.</span></span><code class=\"dargs-code\">: </code><code class=\"dargs-code\">200,</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;</code><span class=\"dargs-key\"><code class=\"dargs-code\">\"save_freq\"</code><span class=\"dargs-doc\">save_freq: <br/>    type: <span class=\"dargs-doc-code\">int</span>, optional, default: <span class=\"dargs-doc-code\">1000</span><hr/>The frequency of saving check point.</span></span><code class=\"dargs-code\">: </code><code class=\"dargs-code\">1000,</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;&nbsp;&nbsp;</code><span><code class=\"dargs-code\">\"_comment\"</code></span><code class=\"dargs-code\">: </code><code class=\"dargs-code\">\"that's&nbsp;all\"</code><br/><code class=\"dargs-code dargs-linebegin\">&nbsp;&nbsp;</code><code class=\"dargs-code\">}</code><br/><code class=\"dargs-code dargs-linebegin\"></code><code class=\"dargs-code\">}</code><br/></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show input.json\n",
    "from deepmd.utils.argcheck import gen_args\n",
    "from dargs.notebook import JSON\n",
    "\n",
    "with open(\"./DeePMD-kit_Tutorial/01.train/input.json\") as f:\n",
    "    JSON(f.read(), gen_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-07 15:13:02.633268: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/deepmd/lib/python3.12/site-packages/tensorflow/python/compat/v2_compat.py:98: disable_resource_variables (from tensorflow.python.ops.resource_variables_toggle) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:root:To get the best performance, it is recommended to adjust the number of threads by setting the environment variables OMP_NUM_THREADS, TF_INTRA_OP_PARALLELISM_THREADS, and TF_INTER_OP_PARALLELISM_THREADS. See https://deepmd.rtfd.io/parallelism/ for more information.\n",
      "DEEPMD INFO    Calculate neighbor statistics... (add --skip-neighbor-stat to skip this step)\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/deepmd/lib/python3.12/site-packages/deepmd/utils/batch_size.py:28: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/deepmd/lib/python3.12/site-packages/deepmd/utils/batch_size.py:28: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "WARNING:deepmd_utils.utils.batch_size:You can use the environment variable DP_INFER_BATCH_SIZE tocontrol the inference batch size (nframes * natoms). The default value is 1024.\n",
      "DEEPMD INFO    training data with min nbor dist: 1.0459205686110267\n",
      "DEEPMD INFO    training data with max nbor size: [4 1]\n",
      "DEEPMD INFO     _____               _____   __  __  _____           _     _  _   \n",
      "DEEPMD INFO    |  __ \\             |  __ \\ |  \\/  ||  __ \\         | |   (_)| |  \n",
      "DEEPMD INFO    | |  | |  ___   ___ | |__) || \\  / || |  | | ______ | | __ _ | |_ \n",
      "DEEPMD INFO    | |  | | / _ \\ / _ \\|  ___/ | |\\/| || |  | ||______|| |/ /| || __|\n",
      "DEEPMD INFO    | |__| ||  __/|  __/| |     | |  | || |__| |        |   < | || |_ \n",
      "DEEPMD INFO    |_____/  \\___| \\___||_|     |_|  |_||_____/         |_|\\_\\|_| \\__|\n",
      "DEEPMD INFO    Please read and cite:\n",
      "DEEPMD INFO    Wang, Zhang, Han and E, Comput.Phys.Comm. 228, 178-184 (2018)\n",
      "DEEPMD INFO    Zeng et al, J. Chem. Phys., 159, 054801 (2023)\n",
      "DEEPMD INFO    See https://deepmd.rtfd.io/credits/ for details.\n",
      "DEEPMD INFO    installed to:         /tmp/tmplz4nqkym/wheel/platlib\n",
      "DEEPMD INFO    source :              \n",
      "DEEPMD INFO    source brach:         \n",
      "DEEPMD INFO    source commit:        \n",
      "DEEPMD INFO    source commit at:     \n",
      "DEEPMD INFO    build float prec:     double\n",
      "DEEPMD INFO    build variant:        cpu\n",
      "DEEPMD INFO    build with tf inc:    /opt/anaconda3/envs/deepmd/lib/python3.12/site-packages/tensorflow/include;/opt/anaconda3/envs/deepmd/lib/python3.12/site-packages/tensorflow/../../../../include\n",
      "DEEPMD INFO    build with tf lib:    \n",
      "DEEPMD INFO    ---Summary of the training---------------------------------------\n",
      "DEEPMD INFO    running on:           Brians-MacBook.local\n",
      "DEEPMD INFO    computing device:     cpu:0\n",
      "DEEPMD INFO    Count of visible GPU: 0\n",
      "DEEPMD INFO    num_intra_threads:    0\n",
      "DEEPMD INFO    num_inter_threads:    0\n",
      "DEEPMD INFO    -----------------------------------------------------------------\n",
      "DEEPMD INFO    training without frame parameter\n",
      "DEEPMD INFO    data stating... (this step may take long time)\n",
      "DEEPMD INFO    built lr\n",
      "DEEPMD INFO    built network\n",
      "DEEPMD INFO    built training\n",
      "WARNING:root:To get the best performance, it is recommended to adjust the number of threads by setting the environment variables OMP_NUM_THREADS, TF_INTRA_OP_PARALLELISM_THREADS, and TF_INTER_OP_PARALLELISM_THREADS. See https://deepmd.rtfd.io/parallelism/ for more information.\n",
      "DEEPMD INFO    initialize model from scratch\n",
      "DEEPMD INFO    start training at lr 1.00e-03 (== 1.00e-03), decay_step 50, decay_rate 0.950006, final lr will be 3.51e-08\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/deepmd/lib/python3.12/site-packages/deepmd/train/trainer.py:1191: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/deepmd/lib/python3.12/site-packages/deepmd/train/trainer.py:1191: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "DEEPMD INFO    batch     200 training time 3.03 s, testing time 0.01 s, total wall time 3.43 s\n",
      "DEEPMD INFO    batch     400 training time 2.07 s, testing time 0.01 s, total wall time 2.11 s\n",
      "DEEPMD INFO    batch     600 training time 2.23 s, testing time 0.01 s, total wall time 2.27 s\n",
      "DEEPMD INFO    batch     800 training time 2.10 s, testing time 0.01 s, total wall time 2.15 s\n",
      "DEEPMD INFO    batch    1000 training time 2.08 s, testing time 0.01 s, total wall time 2.13 s\n",
      "DEEPMD INFO    saved checkpoint model.ckpt\n",
      "DEEPMD INFO    batch    1200 training time 2.22 s, testing time 0.01 s, total wall time 2.52 s\n",
      "DEEPMD INFO    batch    1400 training time 2.13 s, testing time 0.01 s, total wall time 2.17 s\n",
      "DEEPMD INFO    batch    1600 training time 2.06 s, testing time 0.01 s, total wall time 2.11 s\n",
      "DEEPMD INFO    batch    1800 training time 2.01 s, testing time 0.01 s, total wall time 2.06 s\n",
      "DEEPMD INFO    batch    2000 training time 2.12 s, testing time 0.01 s, total wall time 2.16 s\n",
      "DEEPMD INFO    saved checkpoint model.ckpt\n",
      "DEEPMD INFO    batch    2200 training time 2.08 s, testing time 0.01 s, total wall time 2.24 s\n",
      "DEEPMD INFO    batch    2400 training time 2.25 s, testing time 0.01 s, total wall time 2.30 s\n",
      "DEEPMD INFO    batch    2600 training time 2.21 s, testing time 0.01 s, total wall time 2.26 s\n",
      "DEEPMD INFO    batch    2800 training time 2.10 s, testing time 0.01 s, total wall time 2.15 s\n",
      "DEEPMD INFO    batch    3000 training time 2.14 s, testing time 0.01 s, total wall time 2.19 s\n",
      "DEEPMD INFO    saved checkpoint model.ckpt\n",
      "DEEPMD INFO    batch    3200 training time 2.14 s, testing time 0.01 s, total wall time 2.34 s\n",
      "DEEPMD INFO    batch    3400 training time 2.04 s, testing time 0.01 s, total wall time 2.08 s\n",
      "DEEPMD INFO    batch    3600 training time 2.04 s, testing time 0.01 s, total wall time 2.09 s\n",
      "DEEPMD INFO    batch    3800 training time 2.55 s, testing time 0.01 s, total wall time 2.61 s\n",
      "DEEPMD INFO    batch    4000 training time 2.12 s, testing time 0.01 s, total wall time 2.16 s\n",
      "DEEPMD INFO    saved checkpoint model.ckpt\n",
      "DEEPMD INFO    batch    4200 training time 2.07 s, testing time 0.01 s, total wall time 2.25 s\n",
      "DEEPMD INFO    batch    4400 training time 2.03 s, testing time 0.01 s, total wall time 2.07 s\n",
      "DEEPMD INFO    batch    4600 training time 2.03 s, testing time 0.01 s, total wall time 2.07 s\n",
      "DEEPMD INFO    batch    4800 training time 2.04 s, testing time 0.01 s, total wall time 2.08 s\n",
      "DEEPMD INFO    batch    5000 training time 2.21 s, testing time 0.01 s, total wall time 2.26 s\n",
      "DEEPMD INFO    saved checkpoint model.ckpt\n",
      "DEEPMD INFO    batch    5200 training time 2.20 s, testing time 0.01 s, total wall time 2.40 s\n",
      "DEEPMD INFO    batch    5400 training time 2.50 s, testing time 0.04 s, total wall time 2.58 s\n",
      "DEEPMD INFO    batch    5600 training time 2.38 s, testing time 0.01 s, total wall time 2.43 s\n",
      "DEEPMD INFO    batch    5800 training time 2.15 s, testing time 0.01 s, total wall time 2.20 s\n",
      "DEEPMD INFO    batch    6000 training time 2.07 s, testing time 0.01 s, total wall time 2.12 s\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/deepmd/lib/python3.12/site-packages/tensorflow/python/training/saver.py:1068: remove_checkpoint (from tensorflow.python.checkpoint.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/deepmd/lib/python3.12/site-packages/tensorflow/python/training/saver.py:1068: remove_checkpoint (from tensorflow.python.checkpoint.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "DEEPMD INFO    saved checkpoint model.ckpt\n",
      "DEEPMD INFO    batch    6200 training time 2.25 s, testing time 0.01 s, total wall time 2.44 s\n",
      "DEEPMD INFO    batch    6400 training time 2.04 s, testing time 0.01 s, total wall time 2.08 s\n",
      "DEEPMD INFO    batch    6600 training time 2.13 s, testing time 0.01 s, total wall time 2.19 s\n",
      "DEEPMD INFO    batch    6800 training time 2.11 s, testing time 0.01 s, total wall time 2.16 s\n",
      "DEEPMD INFO    batch    7000 training time 2.13 s, testing time 0.01 s, total wall time 2.17 s\n",
      "DEEPMD INFO    saved checkpoint model.ckpt\n",
      "DEEPMD INFO    batch    7200 training time 2.07 s, testing time 0.01 s, total wall time 2.23 s\n",
      "DEEPMD INFO    batch    7400 training time 2.14 s, testing time 0.01 s, total wall time 2.19 s\n",
      "DEEPMD INFO    batch    7600 training time 2.03 s, testing time 0.01 s, total wall time 2.07 s\n",
      "DEEPMD INFO    batch    7800 training time 2.09 s, testing time 0.01 s, total wall time 2.14 s\n",
      "DEEPMD INFO    batch    8000 training time 2.05 s, testing time 0.01 s, total wall time 2.10 s\n",
      "DEEPMD INFO    saved checkpoint model.ckpt\n",
      "DEEPMD INFO    batch    8200 training time 2.08 s, testing time 0.01 s, total wall time 2.25 s\n",
      "DEEPMD INFO    batch    8400 training time 2.04 s, testing time 0.01 s, total wall time 2.09 s\n",
      "DEEPMD INFO    batch    8600 training time 2.07 s, testing time 0.01 s, total wall time 2.11 s\n",
      "DEEPMD INFO    batch    8800 training time 2.05 s, testing time 0.01 s, total wall time 2.09 s\n",
      "DEEPMD INFO    batch    9000 training time 2.05 s, testing time 0.01 s, total wall time 2.09 s\n",
      "DEEPMD INFO    saved checkpoint model.ckpt\n",
      "DEEPMD INFO    batch    9200 training time 2.05 s, testing time 0.01 s, total wall time 2.24 s\n",
      "DEEPMD INFO    batch    9400 training time 2.18 s, testing time 0.01 s, total wall time 2.22 s\n",
      "DEEPMD INFO    batch    9600 training time 2.06 s, testing time 0.01 s, total wall time 2.10 s\n",
      "DEEPMD INFO    batch    9800 training time 2.07 s, testing time 0.01 s, total wall time 2.11 s\n",
      "DEEPMD INFO    batch   10000 training time 2.13 s, testing time 0.01 s, total wall time 2.17 s\n",
      "DEEPMD INFO    saved checkpoint model.ckpt\n",
      "DEEPMD INFO    average training time: 0.0106 s/batch (exclude first 200 batches)\n",
      "DEEPMD INFO    finished training\n",
      "DEEPMD INFO    wall time: 111.771 s\n"
     ]
    }
   ],
   "source": [
    "# ########## Time Warning: 120 secs,C32_CPU ; 13 mins ,C2_CPU ##########\n",
    "! cd DeePMD-kit_Tutorial/01.train/ && dp train input.json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepmd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
